{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOmGhPuYHh5a3KqGVVjpvTd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CT7LBwLySSCi","outputId":"e6867770-3d60-4e8f-b6c7-14db45b39987"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training Logistic Regression...\n"]}],"source":["import pandas as pd\n","import joblib\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from scipy.sparse import hstack\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import GridSearchCV, cross_val_predict\n","from sklearn.metrics import (roc_auc_score, precision_score, recall_score, f1_score,\n","                             confusion_matrix, classification_report, make_scorer)\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import LabelEncoder\n","import xgboost as xgb\n","nltk.download('stopwords', quiet=True)\n","nltk.download('wordnet', quiet=True)\n","nltk.download('omw-1.4', quiet=True)\n","\n","stop_words = set(stopwords.words('english'))\n","lemmatizer = WordNetLemmatizer()\n","\n","def preprocess_text(text: str) -> str:\n","    \"\"\"\n","    Clean and normalize a text string:\n","      - Lowercase\n","      - Remove punctuation/non-word characters\n","      - Tokenize\n","      - Remove stopwords\n","      - Lemmatize tokens\n","    Returns the cleaned text as a single string.\n","    \"\"\"\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Remove punctuation and non-word characters (keep spaces)\n","    text = re.sub(r'\\W+', ' ', text)\n","    # Tokenize by splitting on whitespace\n","    tokens = text.split()\n","    # Remove stopwords and lemmatize each token\n","    tokens = [\n","        lemmatizer.lemmatize(token)\n","        for token in tokens\n","        if token not in stop_words\n","    ]\n","    # Join tokens back into a single string\n","    return ' '.join(tokens)\n","\n","def add_numeric_features(df):\n","    \"\"\"\n","    Add custom numeric features to the DataFrame:\n","      - word_count: number of words in the original title\n","      - exclamation_count: number of '!' characters\n","      - upper_case_count: number of words that are fully uppercase\n","    Modifies the DataFrame in place and returns it.\n","    \"\"\"\n","    # Word count (by splitting on whitespace)\n","    df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n","    # Count of exclamation marks\n","    df['exclamation_count'] = df['text'].apply(lambda x: str(x).count('!'))\n","    # Count of fully uppercase words (e.g., 'BREAKING')\n","    df['upper_case_count'] = df['text'].apply(\n","        lambda x: sum(1 for w in str(x).split() if w.isupper())\n","    )\n","    return df\n","\n","# Load data\n","df_train = pd.read_csv('xy_train.csv')\n","\n","# Add numeric features and preprocess text\n","df_train = add_numeric_features(df_train)\n","df_train['clean_text'] = df_train['text'].apply(preprocess_text)\n","\n","# Vectorize text\n","vectorizer = TfidfVectorizer(max_df=0.9, min_df=5)\n","X_tfidf = vectorizer.fit_transform(df_train['clean_text'])\n","X_num = df_train[['word_count', 'exclamation_count', 'upper_case_count']].values\n","X_train_full = hstack([X_tfidf, X_num]).tocsr()\n","\n","# Encode labels (in case labels are non-numeric)\n","le = LabelEncoder()\n","y_train = le.fit_transform(df_train['label'])\n","\n","# Decide whether it's binary or multiclass\n","is_multiclass = len(le.classes_) > 2\n","roc_auc = make_scorer(roc_auc_score, needs_proba=True, multi_class='ovr' if is_multiclass else 'raise')\n","\n","# --------------------------\n","# Logistic Regression\n","# --------------------------\n","print(\"Training Logistic Regression...\")\n","lr = LogisticRegression(max_iter=1000)\n","lr_param_grid = {'C': [0.01, 0.1, 1, 10]}\n","grid_lr = GridSearchCV(lr, lr_param_grid, scoring=roc_auc, cv=5, n_jobs=-1)\n","grid_lr.fit(X_train_full, y_train)\n","best_lr = grid_lr.best_estimator_\n","print(f\"Best LogisticRegression params: {grid_lr.best_params_}\")\n","\n","y_pred_lr = cross_val_predict(best_lr, X_train_full, y_train, cv=5)\n","print(\"Logistic Regression Classification Report:\")\n","print(classification_report(y_train, y_pred_lr))\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(y_train, y_pred_lr))\n","y_proba_lr = best_lr.predict_proba(X_train_full)\n","print(f\"ROC-AUC (LR): {roc_auc_score(y_train, y_proba_lr, multi_class='ovr' if is_multiclass else 'raise'):.4f}\")\n","\n","# --------------------------\n","# XGBoost\n","# --------------------------\n","print(\"Training XGBoost...\")\n","xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n","xgb_param_grid = {\n","    'n_estimators': [100, 200],\n","    'max_depth': [3, 5],\n","    'learning_rate': [0.01, 0.1]\n","}\n","grid_xgb = GridSearchCV(xgb_clf, xgb_param_grid, scoring=roc_auc, cv=5, n_jobs=-1)\n","grid_xgb.fit(X_train_full, y_train)\n","best_xgb = grid_xgb.best_estimator_\n","print(f\"Best XGBoost params: {grid_xgb.best_params_}\")\n","\n","y_pred_xgb = cross_val_predict(best_xgb, X_train_full, y_train, cv=5)\n","print(\"XGBoost Classification Report:\")\n","print(classification_report(y_train, y_pred_xgb))\n","print(\"Confusion Matrix:\")\n","print(confusion_matrix(y_train, y_pred_xgb))\n","y_proba_xgb = best_xgb.predict_proba(X_train_full)\n","print(f\"ROC-AUC (XGB): {roc_auc_score(y_train, y_proba_xgb, multi_class='ovr' if is_multiclass else 'raise'):.4f}\")\n","\n","# Choose best model\n","auc_lr = roc_auc_score(y_train, y_proba_lr, multi_class='ovr' if is_multiclass else 'raise')\n","auc_xgb = roc_auc_score(y_train, y_proba_xgb, multi_class='ovr' if is_multiclass else 'raise')\n","best_model = best_xgb if auc_xgb >= auc_lr else best_lr\n","print(f\"Selected best model: {best_model.__class__.__name__}\")\n","\n","# Save artifacts\n","joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')\n","joblib.dump(best_model, 'best_model.joblib')\n","joblib.dump(le, 'label_encoder.joblib')  # optional\n","print(\"Saved vectorizer, model, and label encoder.\")\n"]}]}